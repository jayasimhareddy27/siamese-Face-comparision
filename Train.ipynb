{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f4d322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten, Lambda\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K ,layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d865e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return ((preprocess(input_img), preprocess(validation_img)), label)\n",
    "\n",
    "\n",
    "def make_embedding(): \n",
    "    inp = Input(shape=(100,100,3), name='input_image')\n",
    "    \n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "    \n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    # Third block \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=[inp], outputs=d1, name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4790a810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\*'\n",
      "C:\\Users\\jayas\\AppData\\Local\\Temp\\ipykernel_17168\\2805308635.py:10: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(3000)\n",
      "C:\\Users\\jayas\\AppData\\Local\\Temp\\ipykernel_17168\\2805308635.py:11: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(3000)\n",
      "C:\\Users\\jayas\\AppData\\Local\\Temp\\ipykernel_17168\\2805308635.py:12: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(3000)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')\n",
    "\n",
    "\n",
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(3000)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(3000)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df8490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "\n",
    "\n",
    "data = positives.concatenate(negatives)\n",
    "data = data.map(lambda x,y,z: preprocess_twin(x,y,z))\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9f7e7",
   "metadata": {},
   "source": [
    "# Training partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2ceedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8fa767",
   "metadata": {},
   "source": [
    "# Testing partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b2ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695dd152",
   "metadata": {},
   "source": [
    "# 4. Model Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d7a67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_with_margin(margin):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        square_pred = K.square(y_pred)\n",
    "        margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "        return (y_true * square_pred + (1 - y_true) * margin_square)\n",
    "    return contrastive_loss\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "class SiameseModel(Model):\n",
    "    def __init__(self, embedding_model, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_model\n",
    "        self.margin = margin\n",
    "        self.loss_fn = contrastive_loss_with_margin(self.margin)\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        #self.classifier = tf.keras.Sequential([\n",
    "        #    layers.Dense(128, activation='relu'),\n",
    "        #    layers.Dropout(0.3),\n",
    "        #    layers.Dense(64, activation='relu'),\n",
    "        #    layers.Dense(1, activation='sigmoid')  \n",
    "        #])\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        x1, x2 = inputs\n",
    "        embed1 = self.embedding(x1)\n",
    "        embed2 = self.embedding(x2)\n",
    "        distance = euclidean_distance(embed1, embed2)\n",
    "        return distance\n",
    "        #return self.classifier(distance, training=training)\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        (x1, x2), y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            distances = self((x1, x2), training=True)\n",
    "            loss = self.loss_fn(y, distances)\n",
    "            #loss = tf.keras.losses.binary_crossentropy(y, distances)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        (x1, x2), y = data\n",
    "        distances = self((x1, x2), training=False)\n",
    "        loss = self.loss_fn(y, distances)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "554ea40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = SiameseModel(embedding_model=make_embedding(), margin=1.0)\n",
    "siamese_model.compile(optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5740b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input_image']\n",
      "Received: inputs=Tensor(shape=(None, 100, 100, None))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - loss: 2.1284 - val_loss: 0.5828\n",
      "Epoch 2/3\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - loss: 0.5830 - val_loss: 0.6076\n",
      "Epoch 3/3\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - loss: 0.5639 - val_loss: 0.5996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e1f135c680>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model.fit(train_data, validation_data=test_data, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "559ee5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_and_show(model, img1_path, img2_path, threshold=0.5):\n",
    "    img1_tensor = preprocess(img1_path)\n",
    "    img2_tensor = preprocess(img2_path)\n",
    "    img1_tensor = tf.expand_dims(img1_tensor, axis=0)\n",
    "    img2_tensor = tf.expand_dims(img2_tensor, axis=0)\n",
    "\n",
    "    distance = model((img1_tensor, img2_tensor), training=False).numpy()[0][0]\n",
    "\n",
    "    print(f\"\\nImage1: {img1_path}\")\n",
    "    print(f\"Image2: {img2_path}\")\n",
    "    print(f\"Distance = {distance:.4f} | Threshold = {threshold}\")\n",
    "\n",
    "    label = \" SAME\" if distance < threshold else \" DIFFERENT\"\n",
    "    print(f\"Prediction: {label}\")\n",
    "\n",
    "    # Plot\n",
    "    img1 = tf.image.decode_jpeg(tf.io.read_file(img1_path)).numpy()\n",
    "    img2 = tf.image.decode_jpeg(tf.io.read_file(img2_path)).numpy()\n",
    "\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1,2,1); plt.imshow(img1); plt.title(\"Anchor\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,2,2); plt.imshow(img2); plt.title(\"Target\"); plt.axis(\"off\")\n",
    "    plt.suptitle(f\"{label} (Distance: {distance:.4f})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce48db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(ANC_PATH):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        anchor_path = os.path.join(ANC_PATH, filename)\n",
    "        print(f\"\\nComparing: {filename}\")\n",
    "        positive_files = [f for f in os.listdir(POS_PATH) if f.endswith('.jpg')]\n",
    "        positive_path = os.path.join(POS_PATH, positive_files[0])  \n",
    "\n",
    "        verify_and_show(siamese_model, anchor_path, positive_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154fb94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(ANC_PATH):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        anchor_path = os.path.join(ANC_PATH, filename)\n",
    "        print(f\"\\nComparing: {filename}\")\n",
    "        negative_files = [f for f in os.listdir(NEG_PATH) if f.endswith('.jpg')]\n",
    "        negative_path = os.path.join(NEG_PATH, negative_files[15])  \n",
    "\n",
    "        verify_and_show(siamese_model, anchor_path, negative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ea788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
